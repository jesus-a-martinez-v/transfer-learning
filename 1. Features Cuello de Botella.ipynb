{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _Features_ Cuello de Botella\n",
    "\n",
    "Los features cuello de botella son la representación de las imágenes pasada por las capas inmutables (congeladas) de la red.\n",
    "\n",
    "Pre-calcular estos features usando modelos pre-entrenados es una gran manera de ahorrar tiempo y, a su vez, de utilizar modelos o algoritmos más tradicionales como MLPs, SVCs e incluso decision trees.\n",
    "\n",
    "En este notebook calcularemos un par de features cuello de botella usando VGG16."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargando y Pre-procesando una Muestra de Imágenes\n",
    "\n",
    "Calcular features cuello de botella puede ser bastante costoso, tanto a nivel de tiempo como de poder de cómputo.\n",
    "\n",
    "Por esta razón, sólo tomaremos un pequeño subconjunto de las imágenes que usamos en el notebook previo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import random\n",
    "\n",
    "SAMPLE_SIZE = 50\n",
    "\n",
    "image_paths = glob('dog_images/*/*/*')\n",
    "image_paths = random.sample(image_paths, SAMPLE_SIZE)\n",
    "\n",
    "def path_to_tensor(image_path):\n",
    "    img = image.load_img(image_path, target_size=(224, 224))\n",
    "    x = image.img_to_array(img)\n",
    "    \n",
    "    return np.expand_dims(x, axis=0)\n",
    "\n",
    "def paths_to_tensor(image_paths):\n",
    "    tensors = [path_to_tensor(image_path) for image_path in image_paths]\n",
    "    return np.vstack(tensors)\n",
    "\n",
    "# Calculate the image input\n",
    "image_input = preprocess_input(paths_to_tensor(image_paths))\n",
    "\n",
    "print(image_input.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importando VGG16\n",
    "\n",
    "Ahora podemos importar VGG16 sin las capas totalmente conectadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, None, None, 3)     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "model = VGG16(include_top=False)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creando Cuellos de Botella\n",
    "\n",
    "Como pudimos ver anteriormente, la última capa de esta red es de max pooling. Esto nos dará como resultado un tensor tridimensional. Creemos los cuellos de botella:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottlenecked batch shape: (50, 7, 7, 512)\n"
     ]
    }
   ],
   "source": [
    "bottlenecked_batch = model.predict(image_input)\n",
    "print(f'Bottlenecked batch shape: {bottlenecked_batch.shape}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
